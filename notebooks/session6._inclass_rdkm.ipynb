{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We start by importing all of the libaries and functions we'll need "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System tools\n",
    "import os\n",
    "\n",
    "# Data analysis\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from itertools import combinations \n",
    "from tqdm import tqdm\n",
    "\n",
    "# NLP\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Network analysis tools\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (20,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define input file and read data to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = os.path.join(\"..\", \"data\", \"tabular_data\", \"fake_or_real_news.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract all named individuals\n",
    "\n",
    "We use ```spaCy``` to extract only mentions of PERSONS or LOC in the texts.\n",
    "\n",
    "NB: See final comment below under ```Problems```!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_text = data[data[\"label\"] == \"REAL\"][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of lists of entities\n",
    "person_list = []\n",
    "\n",
    "# iterate over every text\n",
    "for doc in tqdm(nlp.pipe(real_text, batch_size=500)):\n",
    "    # temp list\n",
    "    tmp_list = []\n",
    "    # get named entities for each text\n",
    "    for entity in doc.ents:\n",
    "        # if it is a PERSON\n",
    "        if entity.label_ == \"PERSON\":\n",
    "            # append to temporary list\n",
    "            tmp_list.append(entity.text)\n",
    "    # add to output list\n",
    "    person_list.append(tmp_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create edgelist using ```itertools.combinations()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [\"A\", \"B\", \"C\", \"D\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgelist2 = []\n",
    "for sublist in person_list:\n",
    "    edgelist2.extend(list(combinations(sublist, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output edgelist\n",
    "edgelist = []\n",
    "\n",
    "# go over each list or \"document\" one at a time\n",
    "for sublist in person_list:\n",
    "    # get pairings in this doc\n",
    "    edges = list(combinations(sublist, 2))\n",
    "    # for every possible edge\n",
    "    for edge in edges:\n",
    "        # if the two values are the same\n",
    "        if edge[0]==edge[1]:\n",
    "            # do nothing\n",
    "            pass\n",
    "        # otherwise append to output\n",
    "        else:\n",
    "            edgelist.append(edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count occurrences using ```Counter()```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create DF from Counter object, showing each node pair and the edge weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a weighted edgelist\n",
    "weighted_edges = []\n",
    "\n",
    "# use counter on edgelist\n",
    "for key, value in Counter(edgelist).items():\n",
    "    nodeA = key[0]\n",
    "    nodeB = key[1]\n",
    "    weight = value\n",
    "    # append to output\n",
    "    weighted_edges.append((nodeA, nodeB, weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_df = pd.DataFrame(weighted_edges, columns=[\"nodeA\", \"nodeB\", \"weight\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Filter based on edgeweight__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = edges_df[edges_df[\"weight\"]>100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a graph object called ```G```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_edgelist(filtered, \"nodeA\", \"nodeB\", [\"weight\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're just going to use the simplest plotting algorithm. But feel free to experiment with different approaches and see how they perform differently:\n",
    "\n",
    "https://networkx.org/documentation/stable/reference/drawing.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(G, with_labels=True, node_size=20, font_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the folder ```../viz``` exists already for saving the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath_viz = os.path.join('..', 'viz',' network.png')\n",
    "plt.savefig(outpath_viz, dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centrality measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = nx.eigenvector_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvector_df = pd.DataFrame(ev.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvector_df.sort_values(1, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = nx.betweenness_centrality(G)\n",
    "betweenness_df = pd.DataFrame(bc.items()).sort_values(1, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How much of an issue is coreference in the data?\n",
    "\n",
    "- We've said that we're basing this on document co-occurence. But then why are there some node pairs with a greater edge weight than the number of documents?\n",
    "\n",
    "- We could resolve this by changing the final line of our ```spaCy``` pipeline to be something like ```post_entities.append(set(sorted(tmp_entities)))```. \n",
    "    - What does this code do?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "networkx",
   "language": "python",
   "name": "networkx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
